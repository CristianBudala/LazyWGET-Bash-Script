#!/bin/bash
# -----------------------------------------------------------
# TITLE: LazyWGET - Lazy, recursive HTML file download
# AUTHORS: Cristian Budala, Ruslan Gaitur
# DATE: 2025-12
# -----------------------------------------------------------
# DESCRIPTION:
# This script performs recursive, breadth-first download of HTML
# files from a given URL, advancing one level of depth further for each run
#
# USAGE:
# ./lwget <URL>
# ./lwget --reset (to clear the cache)
	#
# DEPENDENCIES:
# - wget: Used for downloading the files
# - grep, awk, cut: Used for link extraction and promise processing & management
# -----------------------------------------------------------

### CONFIG. FILES ###
WORK_DIR="./lwget_cache"
DOWNLOADS_DIR="$WORK_DIR/downloads"
METADATA_DIR="$WORK_DIR/.metadata" # hidden file
PROMISES_FILE="$METADATA_DIR/promises.txt"
LEVEL_FILE="$METADATA_DIR/current_level"

mkdir -p "$DOWNLOADS_DIR"
mkdir -p "$METADATA_DIR"
# -----------------------------------------------------------

usage(){
	cat << EOF

USAGE:
   ./lwget <URL>

OPTIONS:
   <URL>        The base URL where download starts. Only HTTP and HTTPS are accepted. (REQUIRED)
   -h, --help   Print help instructions.
   --reset      Deletes working directory (lwget_cache) and resets progress.

DEPENDENCIES:
   wget, grep, awk, cut

EOF
}

if [[ "$1" == "-h" || "$1" == "--help" ]]; then
	usage
	exit 0
fi

download_file(){
	local url="$1"
	local output_file="$2"
	wget -q -O "$output_file" "$url" # no output (quiet), writes documents to file: -O
}

extract_links(){
    local filename="$1"
	# from the html file, grep prints to stdout only the matching part (-o) of links (not the entire html declaration of the object), splits it by " and prints the second argument
    grep -o 'href="http[^"]*"' "$filename" | awk -F'"' '{print $2}'
}

save_promises(){
	local level="$1"
	local urls="$2"
	while read -r url; do
		echo "$level|$url" >> "$PROMISES_FILE"
	done <<< "$urls"
}

init_level(){
	if [ ! -f "$LEVEL_FILE" ]; then
		echo "0" > "$LEVEL_FILE"
		echo "Initialized links extraction at level 0"
	fi
}

get_current_level(){
	cat "$LEVEL_FILE"
}

get_promises_for_level(){
	local level="$1"
	grep "^$level|" "$PROMISES_FILE" | cut -d "|" -f 2
}

main(){
	if [ $# -eq 0 ]; then
		echo "You must enter an URL!"
		echo "Usage: $0 <URL>"
		exit 1
	fi

	if [ $# -gt 1 ]; then
		echo "You must enter a single <URL>!"
		echo "Usage: $0 <URL>"
		exit 1
	fi

	local url="$1"
	local current_level=$(get_current_level)
	echo "Current level: $current_level"


	if [ "$current_level" -eq 0 ]; then
		echo "--- Level 0: Downloading root file ---"
		local output_file="$DOWNLOADS_DIR/downloaded.html"

		download_file "$url" "$output_file"
		echo ""
		echo "Download complete!"
		echo ""
	
		local urls=$(extract_links "$output_file")
		echo "Found links:"
		echo "$urls"
		echo ""

		save_promises "1" "$urls"
		echo "Promises saved to $PROMISES_FILE"
		echo "1" > "$LEVEL_FILE"
	
	else
		echo "--- Level $current_level: Processing promises ---"
	fi
}

init_level
main "$@"	#calls the main function and passes all command-line arguments to it
